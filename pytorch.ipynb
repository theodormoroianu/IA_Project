{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import torch as th\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torchvision import models, datasets, transforms\n",
    "import torch as th\n",
    "import submission\n",
    "import torchvision.transforms.functional as T\n",
    "\n",
    "dev = torch.device('cpu')\n",
    "if th.cuda.is_available():\n",
    "    dev = torch.device('cuda')\n",
    "\n",
    "# rest accuracy on validation so far\n",
    "best_act = 0.\n",
    "\n",
    "# %%\n",
    "TRANF_POWER = 0.2\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "        transforms.Resize(250),\n",
    "        # transforms.Grayscale(),\n",
    "        # transforms.ColorJitter(2 * TRANF_POWER, 2 * TRANF_POWER, TRANF_POWER, TRANF_POWER),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomRotation(degrees=20),\n",
    "        # transforms.RandomCrop(150, padding=10),\n",
    "        # transforms.RandomAutocontrast(),\n",
    "        # transforms.RandomAdjustSharpness(0.95),\n",
    "        # transforms.RandomResizedCrop(50, scale=(0.8, 1)),\n",
    "        transforms.RandomErasing(scale=(0.02, 0.2)),\n",
    "        # transforms.GaussianBlur(3, sigma=(0.01, 0.01)),\n",
    "        # transforms.RandomHorizontalFlip(),\n",
    "        # transforms.RandomVerticalFlip()\n",
    "])\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    \"data/train_folder\", transform=train_transform\n",
    ")\n",
    "\n",
    "validation_transform = transforms.Compose([\n",
    "        transforms.Resize(250),\n",
    "        transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "validation_dataset = datasets.ImageFolder(\n",
    "    \"data/validation_folder\", transform=validation_transform\n",
    ")\n",
    "\n",
    "test_dataset = datasets.ImageFolder(\n",
    "    \"data/test_folder\", transform=validation_transform\n",
    ")\n",
    "\n",
    "kwargs = {\"num_workers\": 5, \"pin_memory\": True}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=32, shuffle=True, **kwargs\n",
    ")\n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    validation_dataset, batch_size=32, shuffle=False, **kwargs\n",
    ")\n",
    "\n",
    "cnt = 0\n",
    "for i, _ in train_dataset:\n",
    "    cnt += 1\n",
    "    if cnt > 10:\n",
    "        break\n",
    "    plt.imshow(i[0])\n",
    "    plt.show()\n",
    "\n",
    "# %%\n",
    "\n",
    "def make_submission(dataset, contains_labels=False):\n",
    "    with th.no_grad():\n",
    "        net.eval()\n",
    "        acc = 0\n",
    "        fout = open(\"data/submission.csv\", \"w\")\n",
    "        fout.write(\"id,label\\n\")\n",
    "        for id, (img, label) in enumerate(dataset):\n",
    "            result = net(img.to(dev).view(1, img.shape[0], img.shape[1], img.shape[2]))\n",
    "\n",
    "            predicted = result.argmax(dim=1)[0].item()\n",
    "\n",
    "            if contains_labels:\n",
    "                acc += (1 if predicted == label else 0)\n",
    "            \n",
    "            filename = dataset.imgs[id][0].split('/')[3]\n",
    "            fout.write(filename + \",\" + str(predicted) + \"\\n\")\n",
    "\n",
    "        fout.close()\n",
    "\n",
    "        if contains_labels:\n",
    "            nr = len(dataset)\n",
    "            print(f\"Accuracy: {round(acc / nr * 100, 2)}%\")\n",
    "\n",
    "def train(train_loader, optimizer, epoch, criterion):\n",
    "    net.train()\n",
    "\n",
    "    total_loss = []\n",
    "\n",
    "    for data, target in tqdm(train_loader):\n",
    "        data = data.to(dev)\n",
    "        target = target.to(dev)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        prediction = net(data)\n",
    "        loss = criterion(prediction, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "    avg_loss = sum(total_loss) / len(total_loss)\n",
    "    print(f\"Epoch: {epoch}:\")\n",
    "    print(f\"Train Set: Average Loss: {avg_loss:.2f}\")\n",
    "\n",
    "\n",
    "def test(loader, criterion, dataset_name):\n",
    "    net.eval()\n",
    "\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    for data, target in loader:\n",
    "        with torch.no_grad():\n",
    "            data = data.to(dev)\n",
    "            target = target.to(dev)\n",
    "\n",
    "            prediction = net(data)\n",
    "            loss += criterion(prediction, target)\n",
    "\n",
    "            correct += th.sum(prediction.argmax(dim=1) == target)\n",
    "\n",
    "    loss /= len(loader.dataset)\n",
    "\n",
    "    percentage_correct = 100.0 * correct / len(loader.dataset)\n",
    "\n",
    "    print(\n",
    "        dataset_name + \": {:.4f}, Accuracy: {}/{} ({:.2f}%)\".format(\n",
    "            loss, correct, len(loader.dataset), percentage_correct\n",
    "        ),\n",
    "        flush=True\n",
    "    )\n",
    "\n",
    "    return loss.item(), percentage_correct.item()\n",
    "\n",
    "def try_improove(acc):\n",
    "    global best_act\n",
    "    if acc <= best_act:\n",
    "        return\n",
    "\n",
    "    best_act = acc\n",
    "    make_submission(test_dataset, False)\n",
    "\n",
    "    print(\"New best:\", best_act)\n",
    "    th.save(net, \"data/resnet_sav.th\")\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "class Resnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.resnet = models.resnet34(pretrained=True)\n",
    "        self.resnet = models.vgg16()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1000, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(self.resnet(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Resnet().to(dev)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "ep = 0\n",
    "test_acc, train_acc = [], []\n",
    "\n",
    "# %%\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    net.parameters(), lr=3e-4\n",
    ")\n",
    "\n",
    "for e in range(1000):\n",
    "    print(f\"Training epoch #{ep}\", flush=True)\n",
    "    train(train_loader, optimizer, ep, criterion)\n",
    "    train_acc.append(test(train_loader, criterion, \"Train dataset\"))\n",
    "    test_acc.append(test(validation_loader, criterion, \"Validation dataset\"))\n",
    "    try_improove(test_acc[-1][1])\n",
    "    print(\"\")\n",
    "\n",
    "# %%\n",
    "\n",
    "test(train_loader, criterion, \"Train\")\n",
    "test(validation_loader, criterion, \"Validation\")\n",
    "\n",
    "# %%\n",
    "def ConfusionArrays(model, loader, criterion, dataset_name):\n",
    "    model.eval()\n",
    "\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    labels = []\n",
    "    predictions = []\n",
    "\n",
    "    for data, target in tqdm(loader):\n",
    "        with torch.no_grad():\n",
    "            data = data.to(dev)\n",
    "            target = target.to(dev)\n",
    "\n",
    "            prediction = model(data)\n",
    "            \n",
    "            for i in target:\n",
    "                labels.append(i.item())\n",
    "            for i in prediction:\n",
    "                predictions.append(th.argmax(i).item())\n",
    "    \n",
    "    return labels, predictions\n",
    "\n",
    "labels, predicted = ConfusionArrays(net, validation_loader, criterion, \"Validation\")\n",
    "plt.imshow(confusion_matrix(labels, predicted), cmap='gray')\n",
    "plt.show()\n",
    "print(confusion_matrix(labels, predicted))\n",
    "plt.plot([b for a, b in train_acc], label=\"training\")\n",
    "plt.plot([b for a, b in test_acc], label=\"testing\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# th.save(net, \"resnet_sav.th\")\n",
    "# %%\n",
    "net = th.load(\"data/resnet_sav.th\").to(dev)\n",
    "# %%\n",
    "# submission.make_submission(net, True, \"validation\", True)\n",
    "# %%\n"
   ]
  }
 ]
}